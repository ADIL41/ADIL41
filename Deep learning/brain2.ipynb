{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Setting path for dataset\n",
    "train_data_dir = 'D:/python/archive (1)/test'\n",
    "validation_data_dir = 'D:/python/archive (1)/validation'\n",
    "\n",
    "# Check the data directory structure\n",
    "print(\"Train Directory Contents:\", os.listdir(train_data_dir))\n",
    "print(\"Validation Directory Contents:\", os.listdir(validation_data_dir))\n",
    "\n",
    "# Create ImageDataGenerator objects for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training data from the directory with chunking\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,  # Adjust batch size for chunking\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load validation data with chunking\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,  # Adjust batch size for chunking\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Check the steps per epoch\n",
    "print(f\"Steps per epoch: {len(train_generator)}\")\n",
    "print(f\"Validation steps: {len(validation_generator)}\")\n",
    "\n",
    "# Train the model with chunking\n",
    "print(\"Starting model training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=3,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "validation_loss, validation_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Loss: {validation_loss}\")\n",
    "print(f\"Validation Accuracy: {validation_accuracy}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('brain_tumor_cnn_model.h5')\n",
    "\n",
    "model = load_model('brain_tumor_cnn_model.h5')\n",
    "model.summary()\n",
    "\n",
    "# Function to plot images\n",
    "def plot_images(generator):\n",
    "    # Get a batch of images and labels\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot 9 images\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Label: {np.argmax(labels[i])}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plot images from the training dataset\n",
    "plot_images(train_generator)\n",
    "\n",
    "# Plot images from the validation dataset\n",
    "plot_images(validation_generator)\n",
    "\n",
    "# Visualize training performance\n",
    "def plot_performance(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Call the performance plot function\n",
    "plot_performance(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
